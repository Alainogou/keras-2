{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c981c1a9-3e0a-4949-9791-32d47bc9cff3",
   "metadata": {},
   "source": [
    "#### Exercise 1: Regression - Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74dfaa6f-bd99-4bae-b33e-420720d08ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(8, input_shape=(5,), activation= 'sigmoid'))\n",
    "model.add(Dense(4, activation= 'sigmoid'))\n",
    "model.add(Dense(1, activation= 'linear'))\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[keras.metrics.MeanAbsoluteError()] \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888f987-c9f6-497f-b72b-b63bf08d4c20",
   "metadata": {},
   "source": [
    "#### Exercise 2: Regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98dd0792-7000-4c8d-9335-b2a9bfc121e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "\n",
      "X train shape :  (313, 5)\n",
      "\n",
      "First 5 rows are:\n",
      " [[ 1.28377043  0.88466635  0.4869698   0.45570808 -1.19481335]\n",
      " [ 1.28377043  1.28127292  1.36238071  0.67045896 -1.37736562]\n",
      " [ 1.28377043  0.98612384  0.98720461  0.37844321 -1.55991789]\n",
      " [ 1.28377043  0.85699612  0.98720461  0.37503446 -1.19481335]\n",
      " [ 1.28377043  0.8385493   0.7370872   0.39321443 -1.74247016]]\n",
      "\n",
      "The train target : \n",
      "|    |   mpg |\n",
      "|---:|------:|\n",
      "|  0 |    18 |\n",
      "|  1 |    15 |\n",
      "|  2 |    18 |\n",
      "|  3 |    16 |\n",
      "|  4 |    17 |\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "X test shape :  (79, 5)\n",
      "\n",
      "First 5 rows are:\n",
      " [[-1.00254618 -0.55418542 -0.51349982 -0.1135522   1.76253341]\n",
      " [ 0.14061212  0.12834683 -0.51349982  0.31594957  1.25138706]\n",
      " [-1.00254618 -1.0522495  -0.81364071 -1.03959438  0.1925839 ]\n",
      " [-1.00254618 -0.71098337 -0.51349982 -0.44533664  0.08305253]\n",
      " [-1.00254618 -0.84011109 -0.88867593 -0.63736256  0.81326161]]\n",
      "\n",
      "The test target : \n",
      "|     |   mpg |\n",
      "|----:|------:|\n",
      "| 315 |  24.3 |\n",
      "| 316 |  19.1 |\n",
      "| 317 |  34.3 |\n",
      "| 318 |  29.8 |\n",
      "| 319 |  31.3 |\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 17:51:07.803673: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-10-23 17:51:07.804141: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499950000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 7ms/step - loss: 495.3129 - mean_absolute_error: 21.2235\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 477.3531 - mean_absolute_error: 20.9418\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 451.6360 - mean_absolute_error: 20.2464\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 427.7193 - mean_absolute_error: 19.6428\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 410.0008 - mean_absolute_error: 19.1961\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 366.1418 - mean_absolute_error: 17.9959\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 375.6740 - mean_absolute_error: 18.1553\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 373.3880 - mean_absolute_error: 17.9934\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 321.5713 - mean_absolute_error: 16.8511\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 310.6873 - mean_absolute_error: 16.4883\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 296.1816 - mean_absolute_error: 15.8315\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 283.7946 - mean_absolute_error: 15.5012\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 261.9902 - mean_absolute_error: 14.8397\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 248.3952 - mean_absolute_error: 14.4108\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 232.1104 - mean_absolute_error: 13.7770\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 258.3311 - mean_absolute_error: 14.5146\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 215.8409 - mean_absolute_error: 13.1407\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 197.4287 - mean_absolute_error: 12.4457\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 202.2183 - mean_absolute_error: 12.5993\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 205.6180 - mean_absolute_error: 12.7243\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 196.7616 - mean_absolute_error: 12.2346\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 180.3997 - mean_absolute_error: 11.6888\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 175.6961 - mean_absolute_error: 11.3381\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 161.8225 - mean_absolute_error: 10.9063\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 155.7970 - mean_absolute_error: 10.6577\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 158.9732 - mean_absolute_error: 10.7125\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 136.0385 - mean_absolute_error: 9.4057\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 124.6967 - mean_absolute_error: 9.1158\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 129.6523 - mean_absolute_error: 9.0627\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 113.5211 - mean_absolute_error: 8.6029\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 108.7241 - mean_absolute_error: 8.4002\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 95.7059 - mean_absolute_error: 7.7028\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 94.1851 - mean_absolute_error: 7.6823\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 87.4417 - mean_absolute_error: 7.1767\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 79.6110 - mean_absolute_error: 6.8144\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 79.9445 - mean_absolute_error: 6.9489\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 91.0944 - mean_absolute_error: 7.4783\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 78.3420 - mean_absolute_error: 6.8251\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 79.7778 - mean_absolute_error: 6.5460\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 71.9027 - mean_absolute_error: 6.4393\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 61.3882 - mean_absolute_error: 5.8540\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 59.1041 - mean_absolute_error: 5.6857\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 57.9631 - mean_absolute_error: 5.7416\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 52.6642 - mean_absolute_error: 5.2013\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 49.5760 - mean_absolute_error: 4.8580\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 49.5469 - mean_absolute_error: 5.1116\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 47.1826 - mean_absolute_error: 4.8296\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 44.6297 - mean_absolute_error: 4.6014\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 44.6519 - mean_absolute_error: 4.6886\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 45.0932 - mean_absolute_error: 4.6229\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 41.6621 - mean_absolute_error: 4.4351\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 40.0382 - mean_absolute_error: 4.3936\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 39.2907 - mean_absolute_error: 4.3832\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 32.5916 - mean_absolute_error: 4.0770\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 36.3001 - mean_absolute_error: 4.2303\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 36.3504 - mean_absolute_error: 4.2434\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 35.9136 - mean_absolute_error: 4.1888\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 38.2614 - mean_absolute_error: 4.3656\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 35.2216 - mean_absolute_error: 4.0812\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 30.3245 - mean_absolute_error: 3.8794\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 29.5572 - mean_absolute_error: 3.7351\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 29.6560 - mean_absolute_error: 3.9136\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 28.5870 - mean_absolute_error: 3.8431\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 25.6014 - mean_absolute_error: 3.6185\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 31.8286 - mean_absolute_error: 4.0023\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 25.6449 - mean_absolute_error: 3.5687\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 35.6058 - mean_absolute_error: 4.1113\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 23.7256 - mean_absolute_error: 3.3746\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 21.6007 - mean_absolute_error: 3.4004\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 26.0592 - mean_absolute_error: 3.8286\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 21.7941 - mean_absolute_error: 3.4740\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 24.7884 - mean_absolute_error: 3.5925\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 26.1122 - mean_absolute_error: 3.6229\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 21.0483 - mean_absolute_error: 3.2455\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 19.0818 - mean_absolute_error: 3.0786\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 18.3131 - mean_absolute_error: 3.0821\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 22.1107 - mean_absolute_error: 3.1923\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 21.8954 - mean_absolute_error: 3.3676\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 15.0724 - mean_absolute_error: 2.8080\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 17.7876 - mean_absolute_error: 3.0490\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 17.6900 - mean_absolute_error: 2.9649\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 15.5344 - mean_absolute_error: 2.8886\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 19.1612 - mean_absolute_error: 3.1374\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 19.9134 - mean_absolute_error: 3.0388\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 19.4125 - mean_absolute_error: 3.1229\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 16.7380 - mean_absolute_error: 3.0635\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 16.1133 - mean_absolute_error: 2.8556\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 17.0612 - mean_absolute_error: 3.0002\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 15.1209 - mean_absolute_error: 2.7309\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 18.1515 - mean_absolute_error: 2.9273\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 15.1071 - mean_absolute_error: 2.8006\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 13.7733 - mean_absolute_error: 2.7259\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 18.1246 - mean_absolute_error: 3.0541\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 13.4417 - mean_absolute_error: 2.7150\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 14.5807 - mean_absolute_error: 2.7489\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 13.6588 - mean_absolute_error: 2.6547\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 12.0760 - mean_absolute_error: 2.4988\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 12.1748 - mean_absolute_error: 2.5583\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 14.4331 - mean_absolute_error: 2.7883\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 14.9703 - mean_absolute_error: 2.7770\n",
      "\n",
      " Prediction\n",
      " [[24.285559]\n",
      " [18.843088]\n",
      " [26.065744]\n",
      " [25.665588]\n",
      " [25.803469]]\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 74.1579 - mean_absolute_error: 7.0089\n",
      "Mean absolute error 7.008907318115234\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "\n",
    "data= pd.read_csv('./data/auto-mpg.csv')\n",
    "\n",
    "data.drop(['model year', 'origin', 'car name'], axis=1, inplace=True)\n",
    "\n",
    "for col in data.columns:\n",
    "  data[col]=pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(data.drop('mpg', axis=1), data['mpg'], test_size=0.2, shuffle=False)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test= scaler.transform(X_test)\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"\\nX train shape : \", X_train.shape)\n",
    "print(\"\\nFirst 5 rows are:\\n\", X_train[:5])\n",
    "\n",
    "print(\"\\nThe train target : \")\n",
    "print(y_train[:5].to_markdown())\n",
    "\n",
    "print(\"\\n\\nTest\\n\")\n",
    "print(\"X test shape : \", X_test.shape)\n",
    "print(\"\\nFirst 5 rows are:\\n\", X_test[:5])\n",
    "\n",
    "print(\"\\nThe test target : \")\n",
    "print(y_test[:5].to_markdown())\n",
    "\n",
    "\n",
    "#2\n",
    "\n",
    "model= keras.Sequential(\n",
    "    [\n",
    "        Dense(15, input_shape=(X_train.shape[1],), activation='sigmoid'),\n",
    "        Dense(10, activation='sigmoid'),\n",
    "        Dense(1, activation='linear')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[keras.metrics.MeanAbsoluteError()] \n",
    ")\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=5)\n",
    "\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"\\n Prediction\\n\", model.predict(X_test[:5]))\n",
    "\n",
    "#print(\"\\n Mean absolute error \", keras.metrics.MeanAbsoluteError()(y_test.to_numpy(), pred_test.reshape(1, -1)[0]))\n",
    "\n",
    "mae= model.evaluate(X_test, y_test)[1]\n",
    "print(\"Mean absolute error\", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848dba0-b83b-490b-85e5-bc0cb6977739",
   "metadata": {},
   "source": [
    "#### Exercice 3 : Multi-classification - Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c577af67-acd9-47c2-b164-210c0ec3a095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 16)                96        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 277\n",
      "Trainable params: 277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(16, input_shape=(5,), activation= 'sigmoid'))\n",
    "model.add(Dense(8, activation= 'sigmoid'))\n",
    "model.add(Dense(5, activation= 'softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bed219-df3d-44c6-b87e-69976b2145c4",
   "metadata": {},
   "source": [
    "#### Exercise 4: Multi classification - Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40434665-4f6b-4f9d-b801-9b229fd6ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431fb222-77a3-4122-b013-1d80d57a9473",
   "metadata": {},
   "source": [
    "#### Exercise 5: Multi classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e7988-2826-4430-9360-92e11f77a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#1\n",
    "lb= LabelBinarizer()\n",
    "y_train= lb.fit_transform(y_train)\n",
    "y_test= lb.transform(y_test)\n",
    "print(\"The first ten values of the train labels :\\n\",  y_train[:10])\n",
    "\n",
    "#2\n",
    "model= keras.Sequential(\n",
    "    [\n",
    "        Dense(16, input_shape=(X_train.shape[1],), activation='sigmoid'),\n",
    "        Dense(len(y_train[0]), activation='softmax')\n",
    "    ]\n",
    ")\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=5)\n",
    "\n",
    "print(\"Evaluate the accuracy: \",  model.evaluate(X_test, y_test)[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
